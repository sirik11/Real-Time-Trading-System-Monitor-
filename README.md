# Real-Time-Trading-System-Monitor-

# Real‑Time Trading System Monitor

## Overview

This project implements a simulated order matching engine for fixed‑income instruments and
an accompanying observability stack.  It is designed to resemble the architecture of
production trading systems used in the financial services industry, demonstrating
object‑oriented programming, relational database design, system instrumentation,
monitoring, alerting, and container orchestration.

The stack comprises:

* **Order Engine (Java/Spring Boot)** – exposes REST endpoints to place orders,
  maintains an in‑memory price‑time priority order book and persists orders and
  trades to PostgreSQL.  It publishes Prometheus metrics via the Spring Boot
  Actuator.
* **Order Generator (Python)** – simulates random buy and sell orders at a
  configurable rate, hitting the engine and providing a realistic load.  It
  waits for the engine’s health check before starting.
* **PostgreSQL Database** – stores orders, trades and system events.  Startup
  scripts set up the schema and initial indexes.
* **Monitoring Stack** – Prometheus scrapes metrics from the engine and
  Alertmanager evaluates alert rules.  Grafana provides dashboards for
  throughput, latency, error rate, order book depth and uptime.

Everything is packaged in a `docker‑compose.yml` file for one‑command startup.

## Running the Project

Prerequisites:

* [Docker](https://www.docker.com/) and [Docker Compose](https://docs.docker.com/compose/)
* ~4 GB of free RAM and at least 1 CPU core

### Start the stack

Clone the repository and run:

```bash
docker‑compose up --build
```

Docker Compose will start the PostgreSQL database, build the Java order engine,
build the Python order generator, and launch Prometheus and Grafana.  Once the
services are running you can access:

* Engine health endpoint: `http://localhost:8080/health`
* Order API endpoint: `http://localhost:8080/orders`
* Prometheus UI: `http://localhost:9090`
* Grafana UI: `http://localhost:3000` (default login: `admin` / `admin`)

The order generator will wait until the engine returns a healthy status and
then begin submitting orders at the configured rate (default 5 orders/sec).

### Configuration

Environment variables allow tuning behaviour without modifying code:

* `ORDERS_PER_SECOND` – orders per second generated by the Python simulator.
* `SPRING_DATASOURCE_URL`, `SPRING_DATASOURCE_USERNAME`, `SPRING_DATASOURCE_PASSWORD` – set automatically in `docker‑compose.yml` to point at the
  PostgreSQL container.

Prometheus scraping intervals and alert thresholds are defined in
`monitoring/prometheus/prometheus.yml` and `monitoring/prometheus/alert_rules.yml`.

Grafana dashboards are provisioned automatically from
`monitoring/grafana/dashboard.json` using the provided datasource and dashboard
provider configuration.

## Architecture

The engine follows a layered architecture.  Incoming orders hit the REST
controller and are validated and transformed into JPA entities.  The
`MatchingEngine` service manages a per‑instrument order book and uses a
price‑time priority matching algorithm as described in industry sources【919532916412953†L74-L100】.  Orders
are matched against opposing orders and resulting trades are persisted in the
database.  Metrics are recorded via Micrometer counters, gauges and histograms
so that throughput, latency and error rates can be observed in Grafana【836470220456176†L24-L65】.  High
availability of the monitoring stack is considered; Prometheus is configured
with alert rules and could be replicated to avoid single points of failure
【992239022534274†L139-L142】.

## Prometheus Metrics

The engine exposes several application‑specific metrics via the `/actuator/prometheus` endpoint:

| Metric name                    | Type      | Description |
|--------------------------------|-----------|-------------|
| `orders_received_total`        | Counter   | Number of orders received by the API. |
| `orders_matched_total`         | Counter   | Number of orders that were fully or partially matched. |
| `errors_total`                 | Counter   | Number of unexpected errors encountered while processing orders. |
| `order_book_depth`             | Gauge     | Current number of open orders across all instruments. |
| `order_match_latency_seconds`  | Histogram | Distribution of matching times per order; buckets configured in `MetricsConfig`. |

These metrics allow you to monitor reliability and performance.  Grafana
dashboards use PromQL queries such as `rate(orders_received_total[1m])` for
throughput and `histogram_quantile(0.95, rate(order_match_latency_seconds_bucket[5m]))`
for p95 latency.  Following Grafana best practices, dashboards are given
meaningful names, avoid unnecessary refresh rates, document their purpose
and use variables for reuse【659089952061597†L2029-L2045】.

## Extending the Project

This repository provides a solid foundation but can be extended in many ways:

1. **Advanced matching algorithms** – implement pro‑rata or other matching rules as
   described in professional trading systems【919532916412953†L96-L104】.
2. **High availability** – deploy Prometheus in a highly available configuration
   using multiple replicas and long‑term storage backends such as Thanos or
   Cortex【992239022534274†L139-L150】.
3. **Kubernetes deployment** – add Helm charts or Kubernetes manifests to run
   the stack on a cluster with auto‑recovery, liveness/readiness probes and
   horizontal pod autoscaling.
4. **FIX/REST adapters** – support industry standard protocols such as FIX for
   order submission.
5. **Risk management** – incorporate pre‑trade checks, limits and monitoring of
   positions.

By iterating on these features over the course of several weeks, you can
transform this simulation into a polished showcase of your ability to design,
build and operate mission‑critical systems.
